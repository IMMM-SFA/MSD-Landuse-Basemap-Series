{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import rasterstats as rs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rasterstats import zonal_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Zonal Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the input and output directories\n",
    "input_folder = r\".\\CLM\"\n",
    "point_feature_class = r\".\\CLM_XYTableToPoint.shp\"\n",
    "output_folder = r\".\\CLM\\Zonal_Stats\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load the point feature class as a GeoDataFrame\n",
    "gdf = gpd.read_file(point_feature_class)\n",
    "\n",
    "# Ensure that the point dataset has a unique ID column\n",
    "point_id_field = \"pointid\"  # Adjust if the field name differs\n",
    "\n",
    "# List all TIFF files in the input folder\n",
    "tiff_files = [f for f in os.listdir(input_folder) if f.endswith('.tif')]\n",
    "\n",
    "# Loop through each TIFF file and calculate zonal statistics\n",
    "for tiff_file in tiff_files:\n",
    "    input_tiff = os.path.join(input_folder, tiff_file)\n",
    "    \n",
    "    # Compute zonal statistics\n",
    "    zonal_stats = rs.zonal_stats(\n",
    "        gdf, input_tiff, stats=[\"max\"], geojson_out=True\n",
    "    )\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            point_id_field: feature[\"properties\"][point_id_field],\n",
    "            \"MaxValue\": feature[\"properties\"][\"max\"]\n",
    "        }\n",
    "        for feature in zonal_stats\n",
    "    ])\n",
    "\n",
    "    # Define the output file path (CSV instead of DBF)\n",
    "    output_csv = os.path.join(output_folder, f\"ZonalStats_{os.path.splitext(tiff_file)[0]}.csv\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Zonal statistics calculated for {input_tiff} and saved to {output_csv}\")\n",
    "\n",
    "print(\"All zonal statistics have been calculated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging and cleaning completed. Output saved as 'C:\\Users\\jayja\\Documents\\ArcGIS\\Projects\\CLM_Testing\\CLM\\MSE calculation\\merged_output.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the CSV files\n",
    "input_directory = r'.\\CLM\\Zonal_Stats'\n",
    "output_directory = r'.\\CLM\\MSE_calculation'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Initialize an empty list to hold DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(os.path.join(input_directory, filename))\n",
    "        \n",
    "        # Get the base name of the file (without extension)\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Rename columns that contain 'MaxValue' to include the base name\n",
    "        df.columns = df.columns.str.replace('MaxValue', f'{base_name}_Max', case=False)\n",
    "        \n",
    "        # Remove the specific substring from column names\n",
    "        df.columns = df.columns.str.replace('ZonalStats_', '', case=False)\n",
    "        \n",
    "        # Drop columns that contain 'COUNT' or 'Area'\n",
    "        df = df.loc[:, ~df.columns.str.contains('COUNT|AREA', case=False)]\n",
    "        \n",
    "        # Check for duplicate columns and keep the first occurrence\n",
    "        df = df.loc[:, ~df.columns.duplicated(keep='first')]\n",
    "\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Merge all DataFrames on 'pointid'\n",
    "if dataframes:\n",
    "    merged_df = dataframes[0]\n",
    "    for df in dataframes[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on='pointid', how='outer', suffixes=('', '_dup'))\n",
    "        \n",
    "        # Remove duplicate columns that may have been created during the merge\n",
    "        merged_df = merged_df.loc[:, ~merged_df.columns.str.endswith('_dup')]\n",
    "\n",
    "    # Save the merged DataFrame to a new Excel file in the output directory\n",
    "    output_file_path = os.path.join(output_directory, 'merged_output.xlsx')\n",
    "    merged_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "    print(f\"Merging and cleaning completed. Output saved as '{output_file_path}'.\")\n",
    "else:\n",
    "    print(\"No CSV files found to merge.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge PFT to existing PFT list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file successfully created at: C:\\Users\\jayja\\Documents\\ArcGIS\\Projects\\CLM_Testing\\CLM\\MSE calculation\\merged_result.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "merged_output_path = r\".\\CLM\\MSE calculation\\merged_output.xlsx\"\n",
    "pfts_path = r\".\\CLM\\MSE calculation\\PFTs.xlsx\"\n",
    "output_csv_path = r\".\\CLM\\MSE calculation\\merged_result.csv\"\n",
    "\n",
    "try:\n",
    "    # Load the data\n",
    "    merged_output_df = pd.read_excel(merged_output_path)\n",
    "    pfts_df = pd.read_excel(pfts_path)\n",
    "\n",
    "    # Merge the data on 'pointid'\n",
    "    merged_df = pd.merge(merged_output_df, pfts_df, on='pointid', how='outer')\n",
    "\n",
    "    # Save the result to a new CSV file\n",
    "    merged_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Merged file successfully created at: {output_csv_path}\")\n",
    "except FileNotFoundError as fnf_error:\n",
    "    print(f\"File not found: {fnf_error}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabulate the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cell size set to: 30.0000016640515\n",
      "Tabulate Area completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the file paths\n",
    "workspace = r\".\\CLM_Testing\\CLM_Testing.gdb\"\n",
    "input_raster = f\"'{workspace}/CellSta_MSD_2008'\"  # GDAL requires single quotes\n",
    "vector_layer = os.path.join(workspace, \"CLM_Reprojected_PointToRaster.shp\")  # Assuming it's a shapefile\n",
    "output_csv = os.path.join(workspace, \"Tabulate_CLM_MSD_Classes.csv\")\n",
    "\n",
    "# Step 1: Get the cell size of the raster from GDB\n",
    "try:\n",
    "    with rasterio.open(f\"gdal://{input_raster}\") as raster:\n",
    "        cell_size = raster.res[0]  # Assuming square pixels\n",
    "        print(f\"Processing cell size set to: {cell_size}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading raster from GDB: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Tabulate Area (Zonal Statistics)\n",
    "try:\n",
    "    # Load the vector data (geospatial points or polygons)\n",
    "    gdf = gpd.read_file(vector_layer)\n",
    "\n",
    "    # Compute zonal statistics (area covered by each value in raster)\n",
    "    stats = zonal_stats(gdf, f\"gdal://{input_raster}\", stats=[\"count\"], categorical=True, geojson_out=True)\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    tabulate_df = pd.DataFrame([\n",
    "        {**{\"ID\": feature[\"properties\"][\"ID\"]}, **feature[\"properties\"]}\n",
    "        for feature in stats\n",
    "    ])\n",
    "\n",
    "    # Save the output table\n",
    "    tabulate_df.to_csv(output_csv, index=False)\n",
    "    print(\"Tabulate Area completed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during zonal statistics calculation: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge PFTs with Tabulated Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables merged successfully into C:\\Users\\jayja\\Documents\\ArcGIS\\Projects\\CLM_Testing\\CLM\\MSE calculation\\final_merged_output.csv\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "output_folder = r\".\\CLM\\MSE calculation\"\n",
    "exported_table = os.path.join(output_folder, \"Tabulate_CLM_MSD_Classes.csv\")\n",
    "existing_table = os.path.join(output_folder, \"merged_result.csv\")\n",
    "merged_output = os.path.join(output_folder, \"final_merged_output.csv\")\n",
    "\n",
    "# Check if both tables exist\n",
    "if os.path.exists(exported_table) and os.path.exists(existing_table):\n",
    "    # Load the tables as pandas DataFrames\n",
    "    df_exported = pd.read_csv(exported_table)\n",
    "    df_existing = pd.read_csv(existing_table)\n",
    "\n",
    "    # Merge the tables on 'pointid' (left) and 'Value' (right)\n",
    "    df_merged = pd.merge(df_existing, df_exported, left_on='pointid', right_on='VALUE', how='outer')\n",
    "\n",
    "    # Save the merged table to a new CSV file\n",
    "    df_merged.to_csv(merged_output, index=False)\n",
    "    print(f\"Tables merged successfully into {merged_output}\")\n",
    "else:\n",
    "    print(f\"One or both tables not found. Ensure both '{exported_table}' and '{existing_table}' exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Tabulated Area Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names updated successfully in C:\\Users\\jayja\\Documents\\ArcGIS\\Projects\\CLM_Testing\\CLM\\MSE calculation\\final_merged_output.csv\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "output_folder = r\".\\CLM\\MSE calculation\"\n",
    "merged_file = os.path.join(output_folder, \"final_merged_output.csv\")\n",
    "classification_file = os.path.join(output_folder, \"Raw Classification.csv\")\n",
    "\n",
    "# Check if the files exist\n",
    "if os.path.exists(merged_file) and os.path.exists(classification_file):\n",
    "    # Load the merged file and classification file into DataFrames\n",
    "    df_merged = pd.read_csv(merged_file)\n",
    "    df_classification = pd.read_csv(classification_file)\n",
    "    \n",
    "    # Extract the 'MSD Value' and 'Layer Name' columns from classification.csv\n",
    "    # The 'MSD Value' will be used to map to 'VALUE_' columns in the merged file\n",
    "    value_to_layer = {}\n",
    "    \n",
    "    # Iterate through rows in classification.csv to create the mapping from MSD Value to Layer Name\n",
    "    for idx, row in df_classification.iterrows():\n",
    "        msd_value = row['MSD Val']\n",
    "        layer_name = row['Layer Name']\n",
    "        value_to_layer[msd_value] = layer_name\n",
    "    \n",
    "    # Identify the 'VALUE_' columns in the merged DataFrame\n",
    "    value_columns = [col for col in df_merged.columns if 'VALUE_' in col]\n",
    "    \n",
    "    # Create a dictionary to map the 'VALUE_' columns to the corresponding Layer Name\n",
    "    value_column_mapping = {}\n",
    "    \n",
    "    for value_column in value_columns:\n",
    "        # Extract the number from the 'VALUE_' column (e.g., 'VALUE_1' -> 1)\n",
    "        value_number = int(value_column.split('_')[1])\n",
    "        \n",
    "        # Map the MSD Value to the corresponding Layer Name from classification.csv\n",
    "        if value_number in value_to_layer:\n",
    "            value_column_mapping[value_column] = value_to_layer[value_number]\n",
    "    \n",
    "    # Rename the columns in df_merged using the mapping\n",
    "    df_merged.rename(columns=value_column_mapping, inplace=True)\n",
    "\n",
    "    # Save the updated DataFrame back to CSV\n",
    "    df_merged.to_csv(merged_file, index=False)\n",
    "    print(f\"Column names updated successfully in {merged_file}\")\n",
    "else:\n",
    "    print(f\"One or both files '{merged_file}' and '{classification_file}' do not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to: C:\\Users\\jayja\\Documents\\ArcGIS\\Projects\\CLM_Testing\\CLM\\MSE calculation\\final_merge_output_MSD.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the file paths\n",
    "input_file_path = r\".\\CLM\\MSE calculation\\final_merged_output.csv\"\n",
    "output_file_path = r\".\\CLM\\MSE calculation\\final_merge_output_MSD.csv\"\n",
    "\n",
    "# Load the input CSV file\n",
    "data = pd.read_csv(input_file_path)\n",
    "\n",
    "# Select the first column and all columns starting from \"Irrigated Temperate Corn\"\n",
    "start_column = \"Irrigated Temperate Corn\"\n",
    "\n",
    "# Get the list of all column names\n",
    "columns = data.columns.tolist()\n",
    "\n",
    "# Find the index of the starting column\n",
    "start_index = columns.index(start_column)\n",
    "\n",
    "# Slice the DataFrame to include the first column and columns from the starting column onward\n",
    "filtered_data = pd.concat([data.iloc[:, 0], data.iloc[:, start_index:]], axis=1)\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Filtered data saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions calculated and saved to: C:\\Users\\jayja\\Documents\\ArcGIS\\Projects\\CLM_Testing\\CLM\\MSE calculation\\final_merge_output_proportions.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the file path (update it if necessary)\n",
    "file_path = r\".\\CLM\\MSE calculation\\final_merged_output_MSD.csv\"\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Exclude the first column for calculations\n",
    "first_column = data.iloc[:, 0]  # Save the first column\n",
    "data_for_proportions = data.iloc[:, 1:]  # Select the rest of the columns\n",
    "\n",
    "# Calculate proportions for each cell\n",
    "proportions = data_for_proportions.div(data_for_proportions.sum(axis=1), axis=0)\n",
    "\n",
    "# Reattach the first column\n",
    "result = pd.concat([first_column, proportions], axis=1)\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "output_path = r\".\\CLM\\MSE calculation\\final_merge_output_proportions.csv\"\n",
    "result.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Proportions calculated and saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered proportions\n",
      "finished merging\n",
      "Aggregated data saved to: C:\\Users\\jayja\\Documents\\ArcGIS\\Projects\\CLM_Testing\\CLM\\MSE calculation\\aggregated_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "proportions_file = r\".\\CLM\\MSE calculation\\final_merge_output_proportions.csv\"\n",
    "classification_file = r\".CLM\\MSE calculation\\Raw Classification.csv\"\n",
    "output_file = r\".\\CLM\\MSE calculation\\aggregated_output.csv\"\n",
    "\n",
    "# Load the proportions data\n",
    "proportions_df = pd.read_csv(proportions_file)\n",
    "\n",
    "# Load the classification data from the Excel file\n",
    "classification_df = pd.read_csv(classification_file)\n",
    "\n",
    "# Ensure column names in classification data are stripped of extra spaces\n",
    "classification_df['Layer Name'] = classification_df['Layer Name'].str.strip()\n",
    "\n",
    "# Get the name of the first column in proportions_df (e.g., identifiers)\n",
    "first_column_name = proportions_df.columns[0]\n",
    "\n",
    "# Filter proportions columns to include only those matching Layer Name in the classification file\n",
    "matching_columns = [first_column_name] + classification_df['Layer Name'].tolist()\n",
    "filtered_proportions = proportions_df[proportions_df.columns.intersection(matching_columns)]\n",
    "\n",
    "print(\"filtered proportions\")\n",
    "# Reshape the filtered proportions data for aggregation\n",
    "melted_df = filtered_proportions.melt(id_vars=[first_column_name], var_name='Layer Name', value_name='Proportion')\n",
    "\n",
    "# Merge melted proportions data with classification data\n",
    "merged_df = pd.merge(melted_df, classification_df, on='Layer Name', how='inner')\n",
    "print('finished merging')\n",
    "\n",
    "# Aggregate proportions by 'CLM Classification' and the first column\n",
    "aggregated_df = merged_df.groupby([first_column_name, 'CLM Classification'])['Proportion'].sum().reset_index()\n",
    "\n",
    "# Pivot the aggregated data back to wide format\n",
    "final_df = aggregated_df.pivot(index=first_column_name, columns='CLM Classification', values='Proportion').reset_index()\n",
    "\n",
    "# Save the final aggregated data to a CSV file\n",
    "final_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Aggregated data saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add MSE Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE results saved to: C:\\Users\\jayja\\Documents\\ArcGIS\\Projects\\CLM_Testing\\CLM\\MSE calculation\\MSE_Output.csv\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "aggregated_file = r\".\\CLM\\MSE calculation\\aggregated_output.csv\"\n",
    "final_output_file = r\".\\CLM\\MSE calculation\\final_merged_output.csv\"\n",
    "mse_output_file = r\".\\CLM\\MSE calculation\\MSE_Output.csv\"\n",
    "\n",
    "# Load the CSV files\n",
    "aggregated_df = pd.read_csv(aggregated_file)\n",
    "final_output_df = pd.read_csv(final_output_file)\n",
    "\n",
    "# Step 1: Find common columns (excluding 'pointid')\n",
    "common_columns = list(set(aggregated_df.columns).intersection(set(final_output_df.columns)))\n",
    "if 'pointid' in common_columns:\n",
    "    common_columns.remove('pointid')\n",
    "\n",
    "# Step 2: Subset DataFrames to include only common columns\n",
    "aggregated_common = aggregated_df[common_columns]\n",
    "final_output_common = final_output_df[common_columns]\n",
    "\n",
    "# Step 3: Apply the MSE formula\n",
    "# Scale final_merged_output values by dividing by 100\n",
    "final_output_scaled = final_output_common / 100\n",
    "mse_per_cell = (aggregated_common - final_output_scaled) ** 2\n",
    "\n",
    "# Step 4: Calculate row-wise MSE\n",
    "mse_per_row = mse_per_cell.sum(axis=1) / 100\n",
    "aggregated_df['MSE'] = mse_per_row\n",
    "\n",
    "# Step 5: Save the results to MSE_Output.csv\n",
    "aggregated_df.to_csv(mse_output_file, index=False)\n",
    "\n",
    "print(f\"MSE results saved to: {mse_output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point_MSE.csv created with the first and last column: C:\\Users\\jayja\\Documents\\ArcGIS\\Projects\\CLM_Testing\\CLM\\MSE calculation\\point_MSE_V3.csv\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "mse_output_file = r\".\\CLM\\MSE calculation\\MSE_Output.csv\"\n",
    "point_mse_file = r\".\\CLM\\MSE calculation\\point_MSE_V3.csv\"\n",
    "\n",
    "# Load the MSE output file\n",
    "mse_df = pd.read_csv(mse_output_file)\n",
    "\n",
    "# Extract the first and last columns\n",
    "point_mse_df = mse_df.iloc[:, [0, -1]]\n",
    "\n",
    "# Save the new DataFrame to point_MSE.csv\n",
    "point_mse_df.to_csv(point_mse_file, index=False)\n",
    "\n",
    "print(f\"point_MSE.csv created with the first and last column: {point_mse_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
